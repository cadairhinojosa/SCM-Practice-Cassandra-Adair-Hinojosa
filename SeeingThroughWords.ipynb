{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cadairhinojosa/SCM-Practice-Cassandra-Adair-Hinojosa/blob/main/SeeingThroughWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYlbkwoFX42A"
      },
      "outputs": [],
      "source": [
        "#Install the necessary transformers and packages\n",
        "!pip install transformers torch torchvision --quiet\n",
        "!pip install ultralytics --quiet\n",
        "!pip install gradio --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import transformers and packages\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import gradio as gr\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "Owdu2SLNZUNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up the BlipProcessor for image captioning\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model_caption = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
      ],
      "metadata": {
        "id": "PLPZq1RUZg3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up the Yolo Model for object data detection\n",
        "model_yolo = YOLO(\"yolov8n.pt\")  # Use the lightweight version\n"
      ],
      "metadata": {
        "id": "9hFf8xGFZqEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating danger keywords\n",
        "danger_keywords = [\n",
        "    'fire', 'gun', 'knife', 'weapon', 'explosion', 'smoke',\n",
        "    'car', 'truck', 'bus', 'train', 'crowd', 'bear', 'dog',\n",
        "    'cliff', 'motorcycle', 'police car', 'rain', 'drugs','police light', 'danger sign',\n",
        "    'blood', 'crime scene', 'police', 'handcuffs', 'broken', 'glass', 'ambulance', 'crime', 'fight'\n",
        "]\n"
      ],
      "metadata": {
        "id": "9yfAVSQNZuPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Take an image and generate a text description\n",
        "def generate_caption(image):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    out = model_caption.generate(**inputs)\n",
        "    return processor.decode(out[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "aGLzHutJfgl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect the danger key words and check if they match with crime scene words\n",
        "#If else to assist with policy danger key word matching with crime scence to print proper output\n",
        "\n",
        "def detect_danger(image):\n",
        "    results = model_yolo(image)\n",
        "    labels = []\n",
        "    for r in results:\n",
        "        labels += [model_yolo.names[int(c)] for c in r.boxes.cls]\n",
        "\n",
        "    matched = [item for item in labels if item.lower() in danger_keywords]\n",
        "\n",
        "    # Check for specific crime scene keywords first, excluding 'police'\n",
        "    crime_scene_keywords = ['gun', 'knife', 'blood', 'fight', 'handcuffs','police']\n",
        "    if any(word in matched for word in crime_scene_keywords):\n",
        "        return f\"ðŸ”´ Possible Crime Scene: {', '.join(set(matched))}\"\n",
        "    # Check if 'police' is present without other crime scene keywords\n",
        "    elif 'police' in matched and not any(word in matched for word in crime_scene_keywords):\n",
        "        return f\"ðŸŸ¡ Caution: {', '.join(set(matched))}\"\n",
        "    # Check for other danger keywords\n",
        "    elif any(word in matched for word in danger_keywords if word not in crime_scene_keywords and word != 'police'):\n",
        "         return f\"ðŸŸ¡ Caution: {', '.join(set(matched))}\"\n",
        "    else:\n",
        "        return \"ðŸŸ¢ Safe\""
      ],
      "metadata": {
        "id": "_wgBHSEnfi_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Process the image for analysis - Generate a text caption, asses the safety status and display both outputs\n",
        "def analyze_image(img):\n",
        "    caption = generate_caption(img)\n",
        "    danger = detect_danger(img)\n",
        "\n",
        "    # Optional: flag certain keywords from the caption\n",
        "    crime_words = ['arrest', 'weapon', 'blood', 'shooting']\n",
        "    if any(word in caption.lower() for word in crime_words):\n",
        "        danger = \"ðŸ”´ Possible Crime Scene (based on caption)\"\n",
        "\n",
        "    return f\"Caption: {caption}\\n\\nSafety Status: {danger}\"\n",
        "\n",
        "    return f\"Caption: {caption}\\n\\nSafety Status: {danger}\"\n"
      ],
      "metadata": {
        "id": "pnEMxkA4flAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utlizing Gradio library to create a user friendly web interface\n",
        "import gradio as gr\n",
        "\n",
        "gr.Interface(\n",
        "    fn=analyze_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"ðŸ§  Crime Scene Caption & Detection App\",\n",
        "    description=\"Upload an image to receive a description and a danger warning.\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "-M4KIASMPbGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}